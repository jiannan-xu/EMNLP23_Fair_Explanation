{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b52a0c6-f15c-4f9c-ac70-67669c4a9b9b",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd9f0cc-96c7-4862-a75e-dae658e53ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tintn/.conda/envs/atm_bert/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tintn/.conda/envs/atm_bert/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import (\n",
    "    Dataset, \n",
    "    DataLoader, \n",
    "    RandomSampler, \n",
    "    SequentialSampler\n",
    ")\n",
    "\n",
    "import math \n",
    "from transformers import  (\n",
    "    BertPreTrainedModel, \n",
    "    RobertaConfig, \n",
    "    RobertaTokenizerFast\n",
    ")\n",
    "\n",
    "from transformers.optimization import (\n",
    "    AdamW, \n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from scipy.special import softmax\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    matthews_corrcoef,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    ")\n",
    "\n",
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    RobertaClassificationHead,\n",
    "    RobertaConfig,\n",
    "    RobertaModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7c472f-b09a-4b25-b4ac-ab65d7801256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counterfactuals = pd.read_csv('data/EMNLP_Counterfactual_Explanations.csv',index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2705536e-9ed6-4e20-9d57-3f2ec49cdfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Original hate tweet (AI prediction)</th>\n",
       "      <th>Counterfactual explanation (flipped AI prediction: hate to non-hate)</th>\n",
       "      <th>label (ground truth, 1 is hate)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>1364</td>\n",
       "      <td>@abhishek_tri Best solution of corona. Dear @r...</td>\n",
       "      <td>@abhishek_tri Best solution of corona. Dear @r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1015</td>\n",
       "      <td>this is how china is swallowing the World peac...</td>\n",
       "      <td>this is how a country is swallowing the World ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>762</td>\n",
       "      <td>Now i see how the Koreans with Chinese last na...</td>\n",
       "      <td>Now i see how the Koreans with Chinese last na...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1933</td>\n",
       "      <td>@TommysMom5 gave my dick the coronavirus</td>\n",
       "      <td>@TommysMom5 gave my body the coronavirus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>339</td>\n",
       "      <td>@palkisu @rvaidya2000 We all will call it s Ch...</td>\n",
       "      <td>@palkisu @rvaidya2000 We all will call it s Ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1328</td>\n",
       "      <td>@HvBLYabCWxDQEo1 @KingJames Chinese dogs love ...</td>\n",
       "      <td>@HvBLYabCWxDQEo1 @KingJames Chinese dogs love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>352</td>\n",
       "      <td>@chenweihua It’s ccp virus(NOT CHINESE or CHIN...</td>\n",
       "      <td>@chenweihua It’s ccp virus(NOT CHINESE or CHIN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>918</td>\n",
       "      <td>China should pay for what the #CCPVirus is doi...</td>\n",
       "      <td>Someone should pay for what the #CCPVirus is d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1092</td>\n",
       "      <td>@JimmyJo16650328 Pussies.. That's what the Chi...</td>\n",
       "      <td>@JimmyJo16650328 Pussies.. That's what the Chi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>100</td>\n",
       "      <td>China sucks dick and so does 90% of other coun...</td>\n",
       "      <td>China does bad things and so does 90% of other...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1922</td>\n",
       "      <td>@Xbox Are you nibbas making this shit in China...</td>\n",
       "      <td>@Xbox Are you guys making this shit in China I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1783</td>\n",
       "      <td>@R_S_S___ @XHNews so how do we wuhan people ag...</td>\n",
       "      <td>@R_S_S___ @XHNews so how do we wuhan people ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                Original hate tweet (AI prediction)  \\\n",
       "336   1364  @abhishek_tri Best solution of corona. Dear @r...   \n",
       "409   1015  this is how china is swallowing the World peac...   \n",
       "177    762  Now i see how the Koreans with Chinese last na...   \n",
       "152   1933           @TommysMom5 gave my dick the coronavirus   \n",
       "127    339  @palkisu @rvaidya2000 We all will call it s Ch...   \n",
       "389   1328  @HvBLYabCWxDQEo1 @KingJames Chinese dogs love ...   \n",
       "367    352  @chenweihua It’s ccp virus(NOT CHINESE or CHIN...   \n",
       "210    918  China should pay for what the #CCPVirus is doi...   \n",
       "102   1092  @JimmyJo16650328 Pussies.. That's what the Chi...   \n",
       "369    100  China sucks dick and so does 90% of other coun...   \n",
       "417   1922  @Xbox Are you nibbas making this shit in China...   \n",
       "341   1783  @R_S_S___ @XHNews so how do we wuhan people ag...   \n",
       "\n",
       "    Counterfactual explanation (flipped AI prediction: hate to non-hate)  \\\n",
       "336  @abhishek_tri Best solution of corona. Dear @r...                     \n",
       "409  this is how a country is swallowing the World ...                     \n",
       "177  Now i see how the Koreans with Chinese last na...                     \n",
       "152           @TommysMom5 gave my body the coronavirus                     \n",
       "127  @palkisu @rvaidya2000 We all will call it s Ch...                     \n",
       "389  @HvBLYabCWxDQEo1 @KingJames Chinese dogs love ...                     \n",
       "367  @chenweihua It’s ccp virus(NOT CHINESE or CHIN...                     \n",
       "210  Someone should pay for what the #CCPVirus is d...                     \n",
       "102  @JimmyJo16650328 Pussies.. That's what the Chi...                     \n",
       "369  China does bad things and so does 90% of other...                     \n",
       "417  @Xbox Are you guys making this shit in China I...                     \n",
       "341  @R_S_S___ @XHNews so how do we wuhan people ag...                     \n",
       "\n",
       "     label (ground truth, 1 is hate)  \n",
       "336                                0  \n",
       "409                                0  \n",
       "177                                1  \n",
       "152                                0  \n",
       "127                                0  \n",
       "389                                1  \n",
       "367                                0  \n",
       "210                                0  \n",
       "102                                1  \n",
       "369                                1  \n",
       "417                                1  \n",
       "341                                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650033af-cd72-46e1-aba8-9a97b68906e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counterfactuals.columns = ['index','Original','Counterfactual','Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "164b19be-6404-4ebb-ac51-8c9d51dac2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_counterfactuals['Counterfactual']\n",
    "y_test = df_counterfactuals['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca7f983b-f615-4bf5-a7ee-7ece958c06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification\n",
    "max_seq_length = 128\n",
    "test_batch_size = 16\n",
    "num_labels = 2\n",
    "tokenizer_class = RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c11a2889-0d9e-4e55-8bd0-9e14de3bbb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at model were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: @abhishek_tri Best solution of corona. Dear @realDonaldTrump this will scare the shit out of corona virus!\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: this is how a country is swallowing the World peace now and in the future, because they never confess.\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: Now i see how the Koreans with Chinese last names came to live in the peninsula. The Chinese were running away from the problems in mainland China to Korean peninsula since 2 thousand years.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: @TommysMom5 gave my body the coronavirus\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: @palkisu @rvaidya2000 We all will call it s China-origin virus\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: @HvBLYabCWxDQEo1 @KingJames Chinese dogs love to please me. If you're coronavirus free then maybe I'll let you try.\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: @chenweihua It’s ccp virus(NOT CHINESE or CHINA)which killed those innocent all around world...it’s ccp’s plan which is still killing more innocent people all around world... ccp must be held accountable for a better life of all chinese as well as the rest of world people...\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: Someone should pay for what the #CCPVirus is doing to the economies\n",
      "True Label: 0\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: @JimmyJo16650328 Pussies.. That's what the Chinese are known for... retreat Losers!!!\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: China does bad things and so does 90% of other countries in the world. Call me xenophobic 🤷🏻‍♂️\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: @Xbox Are you guys making this shit in China I’m not trying to catch the coronavirus\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n",
      "Sentence: @R_S_S___ @XHNews so how do we wuhan people against the virus？by useing the useless masks？funny\n",
      "True Label: 1\n",
      "Predicted Label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_path = 'model'\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained('roberta-base', do_lower_case=False)\n",
    "\n",
    "# Tokenize the input data\n",
    "tokenized_inputs = tokenizer(X_test.to_list(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Feed the input data to the model and get the predicted outputs\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokenized_inputs['input_ids'], attention_mask=tokenized_inputs['attention_mask'])\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Print the predicted outputs\n",
    "for i, sentence in enumerate(X_test.to_list()):\n",
    "    print(f\"Sentence: {sentence}\\nTrue Label: {y_test.to_list()[i]}\\nPredicted Label: {predictions[i].item()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab8115b2-9526-4c21-92d2-fe74772eca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counterfactuals['pred'] = predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ded971-993b-4e65-8369-d751252a3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counterfactuals.to_csv('data/EMNLP_Counterfactual_updated.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atm_bert",
   "language": "python",
   "name": "atm_bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
